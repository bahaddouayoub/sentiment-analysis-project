{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1 style=\"color:#1a1a1a;\n                    font-size:3em\">\n         ü§ñ Machine learning\n        </h1> \n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Utilisation des r√©seaux multi-couches pour l‚Äôanalyse des üòû sentiments üòÑ.\n       </h2>\n</center>","metadata":{"execution":{"iopub.execute_input":"2022-01-24T17:11:50.522771Z","iopub.status.busy":"2022-01-24T17:11:50.520615Z","iopub.status.idle":"2022-01-24T17:11:50.625279Z"},"papermill":{"duration":0.21357,"end_time":"2022-01-24T22:25:50.317661","exception":false,"start_time":"2022-01-24T22:25:50.104091","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div style=\"font-size:1.3em\">\n    <span>\n    R√©alis√© par :¬∂\n    </span>\n      <ul>\n         <li> BA-HADDOU Ayoub</li>\n\n       \n  \n</div>","metadata":{"papermill":{"duration":0.212479,"end_time":"2022-01-24T22:25:50.740084","exception":false,"start_time":"2022-01-24T22:25:50.527605","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div style=\"font-size:1.5em\">\n    <p>üìú Table des mati√®res:</p>\n    <ul style=\"color:grey;\">\n       <li>\n          <a href=\"#Intro-section\" >Introduction üìñ</a>\n          <ul>\n             <li><a href=\"#overview\">Aper√ßu</a></li>\n             <li><a href=\"#dataset\">Jeu de donn√©es</a></li>\n          </ul>\n       </li>\n       <li>\n          <a href=\"#Analysis-section\">Analyses et Transformations üîé</a>\n          <ul>\n             <li><a href=\"#eda\">Exploration de donn√©es</a></li>\n             <li><a href=\"#trans\">Transformation de donn√©es</a></li>\n          </ul>\n       </li>\n       <li>\n          <a href=\"#pre-processing\">Pr√©-traitement ‚öôÔ∏è</a>\n          <ul>\n             <li><a href=\"#split-data\">Diviser les donn√©es</a></li>\n             <li><a href=\"#Vectorising\">Vectoriser les phrases</a></li>\n          </ul>\n       </li>\n       <li>\n          <a href=\"#model-building\">Construction des mod√®les üõ†Ô∏è</a>\n          <ul>\n             <li><a href=\"#ml-basic\">Mod√®les de base du ML </a></li>\n             <li><a href=\"#ANN\">R√©seaux de neurones artificiels (ANN)</a></li>\n             <li><a href=\"#word-embd\">Word Embedding</a></li>\n             <li><a href=\"#cnn\">R√©seau de Neurones convolutifs (CNN) avec Embedding</a></li>\n          </ul>\n       </li>\n       <li><a href=\"#demo\">Une d√©mo live üßÆ</a></li>\n       <li><a href=\"#Conclusion\">Conclusion üìå</a></li>\n    </ul>\n</div>","metadata":{"papermill":{"duration":0.116359,"end_time":"2022-01-24T22:25:50.974899","exception":false,"start_time":"2022-01-24T22:25:50.85854","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<center id=\"Intro-section\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Introduction üìñ\n        </h2>\n</center>","metadata":{"papermill":{"duration":0.117683,"end_time":"2022-01-24T22:25:51.210562","exception":false,"start_time":"2022-01-24T22:25:51.092879","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div id=\"overview\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Aper√ßu\n        </h3>\n</div>","metadata":{"papermill":{"duration":0.115857,"end_time":"2022-01-24T22:25:51.441546","exception":false,"start_time":"2022-01-24T22:25:51.325689","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Dans le cadre de notre etude Ce projet qui vise a Utilisation des <b>r√©seaux multi-couches</b> pour l‚Äôanalyse des <b>sentiments</b> des phrases issues d‚Äôune base d‚Äôexemples qui contient des phrases √©tiquet√©es avec un sentiment positif ou n√©gatif.\n</span>","metadata":{"papermill":{"duration":0.115342,"end_time":"2022-01-24T22:25:51.672889","exception":false,"start_time":"2022-01-24T22:25:51.557547","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div id=\"dataset\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Jeu de donn√©es\n        </h3>\n</div>","metadata":{"papermill":{"duration":0.115593,"end_time":"2022-01-24T22:25:51.903673","exception":false,"start_time":"2022-01-24T22:25:51.78808","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"\n<span style=\"color:grey; font-size:1.2em\"> Notre jeu de donn√©es a √©t√© cr√©√© pour l'article <b><a href=\"https://dl.acm.org/doi/10.1145/2783258.2783380\">From Group to Individual Labels using Deep Features</a></b>.. Il contient des phrases √©tiquet√©es avec un sentiment positif ou n√©gatif.<br><br>\n<b>Format¬†: score de la phrase / D√©tails</b>\n<br>\nLe score est soit 1 (pour positif) soit 0 (pour n√©gatif)\nLes phrases proviennent de trois sites Web/domaines diff√©rents¬†:<br>\n* [imdb](http://imdb.com)<br>\n* [amazon](http://amazon.com)<br>\n* [yelp](http://yelp.com)\n</span>","metadata":{"papermill":{"duration":0.11635,"end_time":"2022-01-24T22:25:52.135284","exception":false,"start_time":"2022-01-24T22:25:52.018934","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<center id=\"Analysis-section\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Analyses et Transformations üîé\n        </h2>\n</center>","metadata":{"execution":{"iopub.execute_input":"2022-01-24T17:58:30.813618Z","iopub.status.busy":"2022-01-24T17:58:30.812022Z","iopub.status.idle":"2022-01-24T17:58:30.824348Z"},"papermill":{"duration":0.116276,"end_time":"2022-01-24T22:25:52.365622","exception":false,"start_time":"2022-01-24T22:25:52.249346","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div id=\"eda\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Exploration de donn√©es\n        </h3>\n</div>","metadata":{"execution":{"iopub.execute_input":"2022-01-24T18:29:39.022907Z","iopub.status.busy":"2022-01-24T18:29:39.021213Z","iopub.status.idle":"2022-01-24T18:29:39.034502Z"},"papermill":{"duration":0.114006,"end_time":"2022-01-24T22:25:52.593667","exception":false,"start_time":"2022-01-24T22:25:52.479661","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<h4 style=\"color:grey\"> Importation de biblioth√®ques </h4>","metadata":{"execution":{"iopub.execute_input":"2022-01-24T18:49:49.523647Z","iopub.status.busy":"2022-01-24T18:49:49.518861Z","iopub.status.idle":"2022-01-24T18:49:49.594606Z"},"papermill":{"duration":0.117693,"end_time":"2022-01-24T22:25:52.825553","exception":false,"start_time":"2022-01-24T22:25:52.70786","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# importer les biblioth√®ques n√©cessaires\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\n# Mod√®les de apprentissage automatique par sklearn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers","metadata":{"_execution_state":"idle","_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","papermill":{"duration":1.04718,"end_time":"2022-01-24T22:25:54.62491","exception":false,"start_time":"2022-01-24T22:25:53.57773","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-06-18T23:18:21.463282Z","iopub.execute_input":"2022-06-18T23:18:21.463635Z","iopub.status.idle":"2022-06-18T23:18:29.13437Z","shell.execute_reply.started":"2022-06-18T23:18:21.4636Z","shell.execute_reply":"2022-06-18T23:18:29.133567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  ignorer les avertissements\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.135814Z","iopub.execute_input":"2022-06-18T23:18:29.136325Z","iopub.status.idle":"2022-06-18T23:18:29.143958Z","shell.execute_reply.started":"2022-06-18T23:18:29.136275Z","shell.execute_reply":"2022-06-18T23:18:29.142625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Important nos jeu de donn√©es sous les fichier <b>amazon_cells_labelled.txt</b> content les , <b>imdb_labelled.txt</b> et <b>yelp_labelled.txt</b> content  <b>csv</b>.</span>","metadata":{"papermill":{"duration":0.117787,"end_time":"2022-01-24T22:25:54.862444","exception":false,"start_time":"2022-01-24T22:25:54.744657","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Dataset d'amazon\namazon_data = pd.read_csv(\"../input/sentiment-labelled-sentences-data-set/sentiment labelled sentences/amazon_cells_labelled.txt\",delimiter='\\t',header=None, names=[\"text\",\"sentiment\"])\n\n# Dataset d'imdb\nimdb_data = pd.read_csv(\"../input/sentiment-labelled-sentences-data-set/sentiment labelled sentences/imdb_labelled.txt\",delimiter='\\t',header=None, names=[\"text\",\"sentiment\"])\n\n# Dataset de yeld\nyelp_data = pd.read_csv(\"../input/sentiment-labelled-sentences-data-set/sentiment labelled sentences/yelp_labelled.txt\",delimiter='\\t',header=None, names=[\"text\",\"sentiment\"])\n\nDatasets = {\"amazon\":amazon_data,\"imdb\":imdb_data,\"yelp\":yelp_data}","metadata":{"papermill":{"duration":0.1566,"end_time":"2022-01-24T22:25:55.135072","exception":false,"start_time":"2022-01-24T22:25:54.978472","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-18T23:18:29.145498Z","iopub.execute_input":"2022-06-18T23:18:29.145907Z","iopub.status.idle":"2022-06-18T23:18:29.204323Z","shell.execute_reply.started":"2022-06-18T23:18:29.145858Z","shell.execute_reply":"2022-06-18T23:18:29.203554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4 style=\"color:grey\"> Explorant notre jeu de donn√©es </h4>","metadata":{"papermill":{"duration":0.121498,"end_time":"2022-01-24T22:25:55.387049","exception":false,"start_time":"2022-01-24T22:25:55.265551","status":"completed"},"tags":[]}},{"cell_type":"code","source":"amazon_data.sample(7)","metadata":{"papermill":{"duration":0.163141,"end_time":"2022-01-24T22:25:55.674611","exception":false,"start_time":"2022-01-24T22:25:55.51147","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-18T23:18:29.207204Z","iopub.execute_input":"2022-06-18T23:18:29.207509Z","iopub.status.idle":"2022-06-18T23:18:29.229295Z","shell.execute_reply.started":"2022-06-18T23:18:29.207469Z","shell.execute_reply":"2022-06-18T23:18:29.228534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imdb_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.230624Z","iopub.execute_input":"2022-06-18T23:18:29.230833Z","iopub.status.idle":"2022-06-18T23:18:29.240078Z","shell.execute_reply.started":"2022-06-18T23:18:29.230807Z","shell.execute_reply":"2022-06-18T23:18:29.23922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yelp_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.241468Z","iopub.execute_input":"2022-06-18T23:18:29.241916Z","iopub.status.idle":"2022-06-18T23:18:29.254957Z","shell.execute_reply.started":"2022-06-18T23:18:29.241884Z","shell.execute_reply":"2022-06-18T23:18:29.254022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in Datasets:\n    print(\"la taille du dataset \"+str(dataset)+\" est: \"+str(Datasets[dataset].shape[0]))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.255822Z","iopub.execute_input":"2022-06-18T23:18:29.256485Z","iopub.status.idle":"2022-06-18T23:18:29.263151Z","shell.execute_reply.started":"2022-06-18T23:18:29.256442Z","shell.execute_reply":"2022-06-18T23:18:29.262288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Un aper√ßu des donn√©es en utilisant les fonctions <b>info()</b> et <b>describe()</b> du pandas pour examiner les donn√©es. </span>","metadata":{"papermill":{"duration":0.123174,"end_time":"2022-01-24T22:25:56.238575","exception":false,"start_time":"2022-01-24T22:25:56.115401","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for dataset in Datasets.keys():\n    print(\"\\n Les info sur le dataset \"+str(dataset)+\": \\n\")\n    print(Datasets[dataset].info())","metadata":{"papermill":{"duration":0.154556,"end_time":"2022-01-24T22:25:56.515821","exception":false,"start_time":"2022-01-24T22:25:56.361265","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-18T23:18:29.264556Z","iopub.execute_input":"2022-06-18T23:18:29.265282Z","iopub.status.idle":"2022-06-18T23:18:29.306623Z","shell.execute_reply.started":"2022-06-18T23:18:29.265232Z","shell.execute_reply":"2022-06-18T23:18:29.306094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in Datasets.keys():\n    print(\"\\n Une description sur du dataset \"+str(dataset)+\": \\n\")\n    print(Datasets[dataset].describe())","metadata":{"papermill":{"duration":0.179037,"end_time":"2022-01-24T22:25:56.818746","exception":false,"start_time":"2022-01-24T22:25:56.639709","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-18T23:18:29.307635Z","iopub.execute_input":"2022-06-18T23:18:29.308245Z","iopub.status.idle":"2022-06-18T23:18:29.331204Z","shell.execute_reply.started":"2022-06-18T23:18:29.308213Z","shell.execute_reply":"2022-06-18T23:18:29.330395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in Datasets.keys():\n    print(\"\\n Les valeurs null du dataset \"+str(dataset)+\" est: \")\n    print(Datasets[dataset].isna().sum())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-18T23:18:29.334419Z","iopub.execute_input":"2022-06-18T23:18:29.334795Z","iopub.status.idle":"2022-06-18T23:18:29.346356Z","shell.execute_reply.started":"2022-06-18T23:18:29.334751Z","shell.execute_reply":"2022-06-18T23:18:29.3457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Les donn√©es n'ont pas de <b>valeurs manquantes</b>, nous n'effectuerons donc pas un <b>nettoyage des donn√©es.</b> </span>","metadata":{"execution":{"iopub.execute_input":"2022-01-24T19:00:32.005718Z","iopub.status.busy":"2022-01-24T19:00:32.001761Z","iopub.status.idle":"2022-01-24T19:00:32.031031Z"},"papermill":{"duration":0.243516,"end_time":"2022-01-24T22:25:57.305519","exception":false,"start_time":"2022-01-24T22:25:57.062003","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div id=\"trans\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Transformation de donn√©es\n        </h3>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">On va cr√©er un objet de type <b>pandas DataFrame</b> qui contient les donn√©es des trois Datasets.</span>","metadata":{}},{"cell_type":"code","source":"amazon_data['source']='amazon'\nimdb_data['source']='imdb'\nyelp_data['source']='yelp'\n\ndata  = pd.concat(list(Datasets.values()))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.347742Z","iopub.execute_input":"2022-06-18T23:18:29.348093Z","iopub.status.idle":"2022-06-18T23:18:29.358209Z","shell.execute_reply.started":"2022-06-18T23:18:29.348063Z","shell.execute_reply":"2022-06-18T23:18:29.357269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.359308Z","iopub.execute_input":"2022-06-18T23:18:29.359866Z","iopub.status.idle":"2022-06-18T23:18:29.376851Z","shell.execute_reply.started":"2022-06-18T23:18:29.359833Z","shell.execute_reply":"2022-06-18T23:18:29.375978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Analyons donc le nouveau jeu de donn√©es.</span>","metadata":{}},{"cell_type":"code","source":"print(\"la taille du nouveau dataset est: \"+str(data.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.377965Z","iopub.execute_input":"2022-06-18T23:18:29.378161Z","iopub.status.idle":"2022-06-18T23:18:29.388866Z","shell.execute_reply.started":"2022-06-18T23:18:29.378138Z","shell.execute_reply":"2022-06-18T23:18:29.388028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Une description sur du nouveau dataset:\")\ndata.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.390217Z","iopub.execute_input":"2022-06-18T23:18:29.390949Z","iopub.status.idle":"2022-06-18T23:18:29.410072Z","shell.execute_reply.started":"2022-06-18T23:18:29.390904Z","shell.execute_reply":"2022-06-18T23:18:29.409124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"le pourcentage de chaque source:\")\ndata['source'].value_counts().plot(kind='pie', \n                                   autopct='%1.0f%%',\n                                   shadow=True, \n                                   startangle=90, \n                                   pctdistance=0.85,\n                                   explode = (0.1,0.1,0.1),\n                                   colors = ['#f19100','#f21919','#e2b616'],\n                                   figsize=(5, 5))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.411439Z","iopub.execute_input":"2022-06-18T23:18:29.41214Z","iopub.status.idle":"2022-06-18T23:18:29.585976Z","shell.execute_reply.started":"2022-06-18T23:18:29.412095Z","shell.execute_reply":"2022-06-18T23:18:29.585418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"le pourcentage des types de sentiments:\")\ndata.sentiment.value_counts().plot(kind='pie', \n                                   autopct='%1.0f%%',\n                                   shadow=True, \n                                   startangle=180, \n                                   pctdistance=0.85,\n                                   explode = (0.05,0.05),\n                                   colors = ['#5cb696','#e4565c'],\n                                   figsize=(5, 5))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.586827Z","iopub.execute_input":"2022-06-18T23:18:29.587113Z","iopub.status.idle":"2022-06-18T23:18:29.750476Z","shell.execute_reply.started":"2022-06-18T23:18:29.587088Z","shell.execute_reply":"2022-06-18T23:18:29.74954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Cet ensemble de donn√©es a <b>50/50</b> sentiments positifs et n√©gatifs repr√©sent√©s par <b>1 et 0 </b>respectivement.</span>","metadata":{}},{"cell_type":"markdown","source":"<center id=\"pre-processing\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Pr√©-traitement ‚öôÔ∏è\n        </h2>\n</center>","metadata":{"papermill":{"duration":0.235557,"end_time":"2022-01-24T22:26:08.812424","exception":false,"start_time":"2022-01-24T22:26:08.576867","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div id=\"split-data\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Diviser les donn√©es\n        </h3>\n</div>","metadata":{}},{"cell_type":"markdown","source":"\n\n<span style=\"color:grey; font-size:1.2em\">Nous commen√ßons par diviser notre jeu de donn√©es <b>75%</b> pour l'entra√Ænement et <b>25%</b> pour le test.</span>\n","metadata":{}},{"cell_type":"code","source":"sentences = data['text'].values\ny = data['sentiment'].values\n\n# diviser les donn√©es\nsentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, \n                                                                    test_size=0.25, \n                                                                    random_state=1000, \n                                                                    shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.751914Z","iopub.execute_input":"2022-06-18T23:18:29.752449Z","iopub.status.idle":"2022-06-18T23:18:29.763036Z","shell.execute_reply.started":"2022-06-18T23:18:29.7524Z","shell.execute_reply":"2022-06-18T23:18:29.761945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sentences = np.array(sentences_train)\ntrain_labels = np.array(y_train)\ntrain = pd.DataFrame({'sentiment': train_labels, 'text': list(train_sentences)}, columns=['sentiment', 'text'])\n\nprint(\"le pourcentage des types de sentiments pour les donnees d'entra√Ænement:\")\ntrain.sentiment.value_counts().plot(kind='pie', \n                                   autopct='%1.0f%%',\n                                   shadow=True, \n                                   startangle=180, \n                                   pctdistance=0.85,\n                                   explode = (0.05,0.05),\n                                   colors = ['#5cb696','#e4565c'],\n                                   figsize=(5, 5))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.764995Z","iopub.execute_input":"2022-06-18T23:18:29.767093Z","iopub.status.idle":"2022-06-18T23:18:29.918124Z","shell.execute_reply.started":"2022-06-18T23:18:29.767034Z","shell.execute_reply":"2022-06-18T23:18:29.917212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">L'√©chantillon de donn√©es d'apprentissage repr√©sente tr√®s bien l'ensemble de donn√©es</span>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"Vectorising\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Vectoriser les phrases\n        </h3>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">D'aboard on doit cr√©er un vocabulaire de tous les mots uniques dans les phrases. Pour cela on va utiliser `CountVectorizer` fourni par la biblioth√®que `scikit-learn` pour vectoriser les phrases. Ce vocabulaire peut ensuite √™tre utilis√© pour cr√©er un vecteur de caract√©ristiques du nombre de mots.<br> pour mieux comprendre prenant un example issue de notre jeu de donn√©es:</span>","metadata":{}},{"cell_type":"code","source":"sample_text = data['text'][:3]\nfor text in sample_text: print(text)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.919814Z","iopub.execute_input":"2022-06-18T23:18:29.920334Z","iopub.status.idle":"2022-06-18T23:18:29.927011Z","shell.execute_reply.started":"2022-06-18T23:18:29.92029Z","shell.execute_reply":"2022-06-18T23:18:29.926196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = CountVectorizer(min_df=0, lowercase=False)\nvectorizer.fit(sample_text)\nvectorizer.vocabulary_","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.928554Z","iopub.execute_input":"2022-06-18T23:18:29.92903Z","iopub.status.idle":"2022-06-18T23:18:29.950973Z","shell.execute_reply.started":"2022-06-18T23:18:29.928989Z","shell.execute_reply":"2022-06-18T23:18:29.950017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer.transform(sample_text).toarray()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.955558Z","iopub.execute_input":"2022-06-18T23:18:29.955927Z","iopub.status.idle":"2022-06-18T23:18:29.964349Z","shell.execute_reply.started":"2022-06-18T23:18:29.955886Z","shell.execute_reply":"2022-06-18T23:18:29.963335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Cr√©ez les vecteurs de caract√©ristiques pour chaque phrase de l'ensemble d'entra√Ænement et de test¬†:</span>\n","metadata":{}},{"cell_type":"code","source":"vectorizer = CountVectorizer()\nvectorizer.fit(sentences_train)\n\nX_train = vectorizer.transform(sentences_train)\nX_test  = vectorizer.transform(sentences_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:29.966101Z","iopub.execute_input":"2022-06-18T23:18:29.966802Z","iopub.status.idle":"2022-06-18T23:18:30.053433Z","shell.execute_reply.started":"2022-06-18T23:18:29.966748Z","shell.execute_reply":"2022-06-18T23:18:30.052698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"le format final de nos donn√©es d'entra√Ænement est:\\n\\n\",X_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:30.05467Z","iopub.execute_input":"2022-06-18T23:18:30.055129Z","iopub.status.idle":"2022-06-18T23:18:30.062263Z","shell.execute_reply.started":"2022-06-18T23:18:30.055089Z","shell.execute_reply":"2022-06-18T23:18:30.061307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center id=\"model-building\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Construction des mod√®les üõ†Ô∏è\n        </h2>\n</center>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"ml-basic\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Mod√®les de base du ML  \n        </h3>\n</div>\n","metadata":{}},{"cell_type":"code","source":"classifier = DecisionTreeClassifier()\nclassifier.fit(X_train, y_train)\nscore = classifier.score(X_test, y_test)\n\nprint(\"Accuracy: {:.2f} %\".format(score*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:30.063404Z","iopub.execute_input":"2022-06-18T23:18:30.064006Z","iopub.status.idle":"2022-06-18T23:18:30.188739Z","shell.execute_reply.started":"2022-06-18T23:18:30.063954Z","shell.execute_reply":"2022-06-18T23:18:30.187867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">On remarque que le DecisionTreeClassifier a atteint un impressionnant 74.36¬†%, mais regardons comment ce mod√®le fonctionne sur les autres ensembles de donn√©es dont nous disposons. Dans ce script, nous effectuons et √©valuons un ensemble des mod√®les pour chaque ensemble de donn√©es:</span>","metadata":{}},{"cell_type":"code","source":"def prediction(model_name):\n    for dataframe in Datasets.values():\n        Sentences = dataframe['text'].values\n        Y = dataframe['sentiment'].values\n\n        Sentences_train, Sentences_test, Y_train, Y_test = train_test_split(\n            Sentences, Y, test_size=0.25, random_state=1000)\n\n        vectorizer = CountVectorizer(stop_words='english')\n        vectorizer.fit(sentences_train)\n        x_train = vectorizer.transform(Sentences_train)\n        x_test  = vectorizer.transform(Sentences_test)\n\n        model = models[model_name]\n        model.fit(x_train, Y_train)\n        score = model.score(x_test, Y_test)\n        print('Accuracy for {} data with {} model is: {:.2f} %'.format(dataframe['source'][0],model_name, (score*100)))\n    print('\\n'+('-'*70)+'\\n')","metadata":{"papermill":{"duration":0.293917,"end_time":"2022-01-24T22:26:09.377477","exception":false,"start_time":"2022-01-24T22:26:09.08356","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-18T23:18:30.189883Z","iopub.execute_input":"2022-06-18T23:18:30.190113Z","iopub.status.idle":"2022-06-18T23:18:30.197735Z","shell.execute_reply.started":"2022-06-18T23:18:30.190086Z","shell.execute_reply":"2022-06-18T23:18:30.196461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = {\"Logistic Regression\": LogisticRegression(),\n          \"Support Vector Machine\": SVC(),\n          \"Decision Tree\": DecisionTreeClassifier(),\n          \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, max_depth=100, random_state=5000),\n          \"Random Forest\": RandomForestClassifier(max_depth=200, random_state=1000)\n         }\n\nfor model in models: prediction(model)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:30.199446Z","iopub.execute_input":"2022-06-18T23:18:30.199873Z","iopub.status.idle":"2022-06-18T23:18:47.332457Z","shell.execute_reply.started":"2022-06-18T23:18:30.199832Z","shell.execute_reply":"2022-06-18T23:18:47.331493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Comme on peut le voir, les approches ml de base obtiennent des r√©sultats respectables, mais nous n'avons obtenu aucun mod√®le qui fonctionne tr√®s bien sur toutes les donn√©es</span>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"ANN\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  R√©seaux de neurones artificiels (ANN)\n        </h3>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\"> Pour notre R√©seaux de neurones artificiels on va diviser notre jeu de donn√©es <b>75%</b> pour l'entra√Ænement et <b>25%</b> pour le test, et pour la validation on prend <b>30%</b> des donn√©es d'entra√Ænement</span>","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(sentences, y, test_size=0.25)\n\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3)\n\nX_train = vectorizer.transform(X_train)\nX_test  = vectorizer.transform(X_test)\nX_val  = vectorizer.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:47.335403Z","iopub.execute_input":"2022-06-18T23:18:47.335642Z","iopub.status.idle":"2022-06-18T23:18:47.378029Z","shell.execute_reply.started":"2022-06-18T23:18:47.335613Z","shell.execute_reply":"2022-06-18T23:18:47.377365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Maintenant je cr√©e un nouveau mod√®le `Sequential()` puis je ajoute<b> 2 couches:</b> <br> une couche avec l'activation <b>relu</b> avec 10 unit√©s et la deuxieme avec <b>softmax</b> un avec 2 unit√©s afin d'obtenir la <b>certitude</b> pour chaque label.</span>","metadata":{}},{"cell_type":"code","source":"input_dim = X_train.shape[1]  # Number of features\n\nANN_model = Sequential()\nANN_model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\nANN_model.add(layers.Dense(2, activation='softmax'))   ","metadata":{"papermill":{"duration":0.158849,"end_time":"2022-01-24T22:26:09.696155","exception":false,"start_time":"2022-01-24T22:26:09.537306","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-18T23:18:47.38222Z","iopub.execute_input":"2022-06-18T23:18:47.382866Z","iopub.status.idle":"2022-06-18T23:18:47.493104Z","shell.execute_reply.started":"2022-06-18T23:18:47.382825Z","shell.execute_reply":"2022-06-18T23:18:47.492263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">On choisit les param√®tres de la m√©thode `.compile()`. <br>pour le param√®tre <b>loss</b> est <i>sparse_categorical_crossentropy</i> afin de calculer la perte d'entropie crois√©e entre les deux \"Labels\" et les pr√©dictions. pour <b>optimizer</b> on choisit: <i>adam</i> et bien s√ªr <i>accuracy</i> comme <b>metrics</b> </span>","metadata":{}},{"cell_type":"code","source":"ANN_model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer = \"adam\", \n                  metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:47.494536Z","iopub.execute_input":"2022-06-18T23:18:47.494886Z","iopub.status.idle":"2022-06-18T23:18:47.505426Z","shell.execute_reply.started":"2022-06-18T23:18:47.494845Z","shell.execute_reply":"2022-06-18T23:18:47.50469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Voyons un <b>summary<b> des param√®tres de notre mod√®le</span>","metadata":{}},{"cell_type":"code","source":"ANN_model.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-18T23:18:47.506642Z","iopub.execute_input":"2022-06-18T23:18:47.507307Z","iopub.status.idle":"2022-06-18T23:18:47.518876Z","shell.execute_reply.started":"2022-06-18T23:18:47.507274Z","shell.execute_reply":"2022-06-18T23:18:47.517986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Cr√©e un objet contenant l'historique de notre formation de mod√®le:</span>","metadata":{}},{"cell_type":"code","source":"history = ANN_model.fit(X_train, y_train,\n                    epochs=20,\n                    verbose=True,\n                    validation_data=(X_val, y_val),\n                    batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:47.522139Z","iopub.execute_input":"2022-06-18T23:18:47.52243Z","iopub.status.idle":"2022-06-18T23:18:54.328459Z","shell.execute_reply.started":"2022-06-18T23:18:47.522389Z","shell.execute_reply":"2022-06-18T23:18:54.327551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">C'est temps d' <b>√©valuer</b> notre mod√®le √† la fois sur les donn√©es d'entra√Ænement et de test et d'obtenir <b>scores</b> de pr√©cision.</span>","metadata":{}},{"cell_type":"code","source":"loss, accuracy = ANN_model.evaluate(X_train, y_train, verbose=False)\nprint(\"Accuracy sur les donn√©es d'entra√Ænement est: {:.2f} %\".format(accuracy*100))\nloss, accuracy = ANN_model.evaluate(X_test, y_test, verbose=False)\nprint(\"Accuracy sur les donn√©es du test est: {:.2f} %\".format(accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:54.330203Z","iopub.execute_input":"2022-06-18T23:18:54.330433Z","iopub.status.idle":"2022-06-18T23:18:54.416893Z","shell.execute_reply.started":"2022-06-18T23:18:54.330404Z","shell.execute_reply":"2022-06-18T23:18:54.416305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Comme je peux le voir, j'ai atteint un meilleur score avec un r√©seau de neurones artificiels pour nos donn√©es du test qui provient de diff√©rentes sources</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Tra√ßons l'historique de nos score de mod√®le sur les donn√©es d'entra√Ænement et de validation pour chaque <b>Epoch</b>.</span>","metadata":{}},{"cell_type":"code","source":"def plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    x = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, acc, 'b', label='Training accuracy')\n    plt.plot(x, val_acc, 'r', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, 'b', label='Training loss')\n    plt.plot(x, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:54.417922Z","iopub.execute_input":"2022-06-18T23:18:54.418268Z","iopub.status.idle":"2022-06-18T23:18:54.42409Z","shell.execute_reply.started":"2022-06-18T23:18:54.418235Z","shell.execute_reply":"2022-06-18T23:18:54.423549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:54.425104Z","iopub.execute_input":"2022-06-18T23:18:54.425318Z","iopub.status.idle":"2022-06-18T23:18:54.848802Z","shell.execute_reply.started":"2022-06-18T23:18:54.425294Z","shell.execute_reply":"2022-06-18T23:18:54.847921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">testons maintenant notre mod√®le avec une simple phrase üòÉ <b>positive</b> </span>","metadata":{}},{"cell_type":"code","source":"# string pour le test\nphrase = \"Rabat is a beautiful, calm and lovely place\"\n\nprediction_test = ANN_model.predict(vectorizer.transform([phrase]))\nclass_test = np.argmax(prediction_test)\n\nprint(\"Le Label pr√©dite pour la phrase est: \",class_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:54.849868Z","iopub.execute_input":"2022-06-18T23:18:54.850085Z","iopub.status.idle":"2022-06-18T23:18:55.151645Z","shell.execute_reply.started":"2022-06-18T23:18:54.850059Z","shell.execute_reply":"2022-06-18T23:18:55.150962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div id=\"word-embd\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  Word Embedding\n        </h3>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Le <b>Word Embedding</b> est une technique permet de repr√©senter chaque mot d'un dictionnaire par un <b>vecteur de nombres r√©els</b>. Cette nouvelle repr√©sentation a ceci de particulier que les mots apparaissant dans des <b>contextes similaires</b> poss√®dent des vecteurs correspondants qui sont relativement <b>prochespositive</b>. </span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Pour presenter des mots sous forme de vecteurs (ce qui est la mani√®re courante d'utiliser le texte dans les r√©seaux de neurones) il y a deux fa√ßons possibles de repr√©senter un mot sous forme de vecteur sont <b>One-hot encoding</b> et <b>Word embeddings</b>. </span>","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"font-size:1.2em\">One-Hot Encoding</h4>\n\n<span style=\"color:grey; font-size:1.2em\">La premi√®re fa√ßon de repr√©senter un mot sous forme de vecteur consiste √† cr√©er un One-Hot Encoding, qui se fait simplement en prenant un vecteur de la longueur du vocabulaire avec une entr√©e pour chaque mot du corpus.</span>","metadata":{}},{"cell_type":"markdown","source":"<h4 style=\"font-size:1.2em\">Word embeddings</h4>\n\n<span style=\"color:grey; font-size:1.2em\">Cette m√©thode repr√©sente les mots sous forme de \"dense word vectors\" qui sont entra√Æn√©s contrairement au dense One-Hot Encoding qui est cod√© en dur. Cela signifie que les int√©grations de mots collectent plus d'informations dans moins de dimensions.</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Voice un example de Word Embedding sur l'un des reviews:</span>","metadata":{}},{"cell_type":"markdown","source":"<div id=\"cnn\">\n        <h3 style=\"color:#1a1a1a;\n                    font-size:2em\">\n         ‚Æû  R√©seau de Neurones convolutifs (CNN) avec Embedding\n        </h3>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\"> Pour notre R√©seaux de neurones convolutifs on va diviser notre jeu de donn√©es <b>80%</b> pour l'entra√Ænement et <b>20%</b> pour le test, et pour la validation on prend <b>20%</b> des donn√©es d'entra√Ænement</span>","metadata":{}},{"cell_type":"code","source":"sentences_train, sentences_val, y_train, y_val = train_test_split(sentences, y, test_size=0.2, random_state=1000)\nsentences_train, sentences_test, y_train, y_test = train_test_split(sentences_train, y_train, test_size=0.2, random_state=1000)\n\n# definir notre tokenizer\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(sentences_train)\n\n# tokenizer nos donn√©es\nX_train = tokenizer.texts_to_sequences(sentences_train)\nX_test = tokenizer.texts_to_sequences(sentences_test)\nX_val = tokenizer.texts_to_sequences(sentences_val)\n\n# la taille du vocabulaire\nvocab_size = len(tokenizer.word_index) + 1\nmaxlen = 100\n\n# transformer la forme des donn√©es\nX_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\nX_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\nX_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:55.15252Z","iopub.execute_input":"2022-06-18T23:18:55.152748Z","iopub.status.idle":"2022-06-18T23:18:55.242954Z","shell.execute_reply.started":"2022-06-18T23:18:55.152721Z","shell.execute_reply":"2022-06-18T23:18:55.242169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  cr√©er un nouveau mod√®le\nembedding_dim = 100\nEMB_CNN = Sequential()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:55.244226Z","iopub.execute_input":"2022-06-18T23:18:55.244531Z","iopub.status.idle":"2022-06-18T23:18:55.252217Z","shell.execute_reply.started":"2022-06-18T23:18:55.244493Z","shell.execute_reply":"2022-06-18T23:18:55.251408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # ajout des couches\nEMB_CNN.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\nEMB_CNN.add(layers.Conv1D(128, 5, activation='relu'))\nEMB_CNN.add(layers.GlobalMaxPooling1D())\nEMB_CNN.add(layers.Dense(10, activation='relu'))\nEMB_CNN.add(layers.Dense(2, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:55.253298Z","iopub.execute_input":"2022-06-18T23:18:55.253505Z","iopub.status.idle":"2022-06-18T23:18:55.310094Z","shell.execute_reply.started":"2022-06-18T23:18:55.253481Z","shell.execute_reply":"2022-06-18T23:18:55.309107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# On choisit les param√®tres du mod√®le\nEMB_CNN.compile(loss='sparse_categorical_crossentropy',\n                  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07), \n                  metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:55.312114Z","iopub.execute_input":"2022-06-18T23:18:55.312628Z","iopub.status.idle":"2022-06-18T23:18:55.323252Z","shell.execute_reply.started":"2022-06-18T23:18:55.312585Z","shell.execute_reply":"2022-06-18T23:18:55.322598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EMB_CNN.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:55.324089Z","iopub.execute_input":"2022-06-18T23:18:55.324655Z","iopub.status.idle":"2022-06-18T23:18:55.335834Z","shell.execute_reply.started":"2022-06-18T23:18:55.324625Z","shell.execute_reply":"2022-06-18T23:18:55.335203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = EMB_CNN.fit(X_train, y_train,\n                    epochs=20,\n                    verbose=True,\n                    validation_data=(X_val, y_val),\n                    batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:18:55.336846Z","iopub.execute_input":"2022-06-18T23:18:55.337619Z","iopub.status.idle":"2022-06-18T23:19:33.665798Z","shell.execute_reply.started":"2022-06-18T23:18:55.337571Z","shell.execute_reply":"2022-06-18T23:19:33.665013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = EMB_CNN.evaluate(X_train, y_train, verbose=False)\nprint(\"Accuracy sur les donn√©es d'entra√Ænement est: {:.2f} %\".format(accuracy*100))\nloss, accuracy = EMB_CNN.evaluate(X_test, y_test, verbose=False)\nprint(\"Accuracy sur les donn√©es du test est: {:.2f} %\".format(accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:19:33.666939Z","iopub.execute_input":"2022-06-18T23:19:33.667149Z","iopub.status.idle":"2022-06-18T23:19:34.253767Z","shell.execute_reply.started":"2022-06-18T23:19:33.667124Z","shell.execute_reply":"2022-06-18T23:19:34.252882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-18T23:19:34.254988Z","iopub.execute_input":"2022-06-18T23:19:34.255659Z","iopub.status.idle":"2022-06-18T23:19:34.643694Z","shell.execute_reply.started":"2022-06-18T23:19:34.255619Z","shell.execute_reply":"2022-06-18T23:19:34.642136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Encore une fois, nous avons atteint un meilleur score avec plus de couches pour notre <b>CNN</b></span>","metadata":{}},{"cell_type":"markdown","source":"<center id=\"demo\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Une d√©mo live üßÆ\n        </h2>\n</center>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"color:grey; font-size:1.2em\">Enfin voici un champ de saisie en utilisant <b>ipywidgets, IPython.display</b> pour d√©finir un widget et le contenu d'affichage aisnsi que l'input field. On utilise ce champ de saisie pour tester des phrases al√©atoires de nos choix et obtenir une prediction et la certitude pour le Label.</span>","metadata":{}},{"cell_type":"code","source":"from ipywidgets import interact, widgets\nfrom IPython.display import display, Markdown, Latex, clear_output\n\n# d√©finir les param√®tres du widget\ntext = widgets.Text(\n    value='',\n    placeholder='type your description here',\n    description='Description:',\n    disabled=False\n)\n# affichage du text\ndisplay(text)\n\n# appeler le widget\ndef callback(wdgt):\n    clear_output()## Creating model\n    display(text)\n    # prendre la valeur d'input\n    desc = wdgt.value\n    \n    # faire une prediction sur la description\n    prediction_test = EMB_CNN.predict(vectorizer.transform([desc]))\n    \n    # obtenir la classe du text\n    class_test = np.argmax(prediction_test)\n    \n    # obtenir la certitude du prediction\n    certainty = prediction_test[0][class_test]\n    \n    # mapper chaque class a une phrase correspondante\n    result = 'positive üòÉ' if class_test == 1 else 'negative üòû'\n    \n    # afficher le resultat\n    display(Markdown('La description: \"{}\" est  {:.2f} %   {}'.format(desc,certainty*100,result)))\n\ntext.on_submit(callback)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:19:34.645042Z","iopub.execute_input":"2022-06-18T23:19:34.645288Z","iopub.status.idle":"2022-06-18T23:19:34.72571Z","shell.execute_reply.started":"2022-06-18T23:19:34.645255Z","shell.execute_reply":"2022-06-18T23:19:34.724955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center id=\"Conclusion\">\n        <h2 style=\"color:#1a1a1a;\n                    font-size:2em\">\n        Conclusion üìå\n        </h2>\n</center>","metadata":{"papermill":{"duration":0.218439,"end_time":"2022-01-24T22:26:28.433396","exception":false,"start_time":"2022-01-24T22:26:28.214957","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div style=\"color:grey; font-size:1.2em\">Le travail que j'ai r√©alis√© a consist√© √† exploirer le cycle de vie d'un project de Data Science en general et du Machine Learning et Deep Learning en particulier. On bien appris comment analyser et transformer les donn√©es, dans la partie du Pr√©-traitement on a diviser les donn√©es et vectoriser les phrases, et derni√®rement la construction des mod√®les en essayant diff√©rentes approches: Mod√®les de base, les R√©seaux de neurones artificiels et finalement les R√©seau de Neurones convolutifs.\n<br>\n<br>\n<span style=\"color:black; font-size:1.2em; background-color:#FFFFA6\">Ce projet a permis d'acqu√©rir les techniques d'utiliser des r√©seaux multi-couches pour l‚Äôanalyse et pr√©dire les sentiments</span>\n</div>","metadata":{"execution":{"iopub.execute_input":"2022-01-24T22:26:28.820806Z","iopub.status.busy":"2022-01-24T22:26:28.81918Z","iopub.status.idle":"2022-01-24T22:26:28.844869Z","shell.execute_reply":"2022-01-24T22:26:28.843608Z"},"papermill":{"duration":0.217872,"end_time":"2022-01-24T22:26:28.844989","exception":false,"start_time":"2022-01-24T22:26:28.627117","status":"completed"},"tags":[]}}]}